# GAIIC2022_track1_rank11
2022人工智能技术创新大赛-赛道1-电商关键属性匹配 
链接：https://www.heywhale.com/home/competition/620b34c41f3cf500170bd6ca/content/2
## 数据分析
#### 1. 原始数据处理
原始数据分为有标签（5万）和无标签（10万）
通过从有标签数据的title中检索属性，将原本的正样本无标签数据构造成有标签数据
#### 2. 数据增强
数据本身正负样本比例为8:2，需要构造负样本
• 将属性随机替换
• 随机交换标题中关键属性的位置
• 删除部分关键属性
经实验证明，当正负样本比例为1:2，效果最佳，实验数据约40万
## 模型
#### 1. CNN 
在一位大佬分享的baseline上做了一些改动，初赛单模效果能到0.93+，最终CNN是跑了五折再进行投票融合,成绩能到0.94+
• 调整了正则化参数
• 融合了最大池化和平均池化来提取更多信息
• 在文字和图片特征concat后添加了attention模块
#### 2. BERT
使用ChineseBert在全部title上使用MLM任务预训练。文字输入Bert得到的Embedding结果与图片特征（经过降维处理）concat做13分类，初赛A榜分数0.93
• concat后处理结构与CNN相同
#### 3. Visual Bert
直接将图片向量降维到1024后与文字向量一同输入visualbert, 使用Huggface预训练权重，复赛A榜分数0.909
• 使用transform结构6层结果与12层结果相差不大
• 对图片向量的输入方式进行了探索，发现复制图片向量并单独经过处理后进行输入，有小幅的结果提升
## 一些尝试
• 使用jieba 分词，对字典根据数据集进行了调整（有提升）
• 分析数据发现图文、版型、领型预测效果不好，单独对其进行二分类（没提升）
• 复赛将训练数据分布设置成测试数据（没提升）
## 总结
总体来说我们组这次比赛开始使用的CNN网络，对这个网络进行了一系列的实验，
单模五折到0.94+后，再做调整效果就不明显了，但因为CNN这个模型非常小，只有12M，所以不用考虑模型大小的限制，最后方案融合了BERT,Visual BERT模型。
## 最后
BERT，Visual BERT这两个模型我们也尝试了很多种改进，效果不太理想，也希望可以看看别人的方案学习一下。
第一次打比赛，还有很多需要改进的地方，继续加油

